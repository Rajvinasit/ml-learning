{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RAJVI\\anaconda3\\envs\\pin\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9285 - loss: 0.2703 - val_accuracy: 0.9287 - val_loss: 0.2658\n",
      "Epoch 2/5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9303 - loss: 0.2557 - val_accuracy: 0.9287 - val_loss: 0.2572\n",
      "Epoch 3/5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - accuracy: 0.9330 - loss: 0.2464 - val_accuracy: 0.9287 - val_loss: 0.2571\n",
      "Epoch 4/5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9296 - loss: 0.2552 - val_accuracy: 0.9287 - val_loss: 0.2579\n",
      "Epoch 5/5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step - accuracy: 0.9282 - loss: 0.2590 - val_accuracy: 0.9287 - val_loss: 0.2574\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n",
      "Validation Accuracy: 0.9286719849835758\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load Data\n",
    "train_data = pd.read_csv(r'C:\\Users\\RAJVI\\MACHINE LEARNING\\multiple_LR\\Homework\\train_tweet.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\RAJVI\\MACHINE LEARNING\\multiple_LR\\Homework\\test_tweets.csv')\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = text.strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "train_data['cleaned_text'] = train_data['tweet'].apply(preprocess_text)\n",
    "test_data['cleaned_text'] = test_data['tweet'].apply(preprocess_text)\n",
    "\n",
    "# Step 3: Tokenization and Padding\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_data['cleaned_text'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['cleaned_text'])\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "y_train = np.array(train_data['label'])\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create a Simple Model\n",
    "model = Sequential([\n",
    "    Embedding(max_words, 128, input_length=max_len),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "val_predictions = (model.predict(X_val) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f'Validation Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
